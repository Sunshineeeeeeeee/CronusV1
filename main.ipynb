{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from datetime import datetime\n",
    "\n",
    "df = pd.read_csv(\"/Users/aleksandr/Desktop/Meta_Test.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting preprocessing with 570771 rows\n",
      "After filtering trading hours: 282810 rows\n",
      "After cleaning outliers: 282301 rows\n",
      "Final clean dataset: 278585 rows\n",
      "\n",
      "Outlier counts by detection method:\n",
      "  zscore: 64\n",
      "  extreme_deviation: 69\n",
      "  isolated_point: 390\n",
      "  price_reversal: 93\n",
      "  timestamp_group: 34\n",
      "  price_velocity: 3703\n",
      "  suspicious_cluster: 52\n",
      "  wavelet_outlier: 24\n"
     ]
    }
   ],
   "source": [
    "from clean import preprocess_tick_data\n",
    "\n",
    "df_clean, df_diagnostics, outlier_counter = preprocess_tick_data(df)\n",
    "df = df_clean\n",
    "df = df.drop(columns=\"VOLATILITY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volatility estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimating advanced tick-level volatility for 278585 ticks...\n",
      "Computing wavelet-based volatility for META.O...\n",
      "Completed advanced tick-level volatility estimation\n"
     ]
    }
   ],
   "source": [
    "from volatility import estimate_tick_volatility\n",
    "\n",
    "df = estimate_tick_volatility(df, method = 'wavelet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Value</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Volatility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-01-30 09:30:00.740000+00:00</td>\n",
       "      <td>694.24</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-01-30 09:30:00.740000+00:00</td>\n",
       "      <td>694.17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-01-30 09:30:00.740000+00:00</td>\n",
       "      <td>694.17</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-01-30 09:30:00.740000+00:00</td>\n",
       "      <td>694.11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-01-30 09:30:00.740000+00:00</td>\n",
       "      <td>694.10</td>\n",
       "      <td>249.0</td>\n",
       "      <td>0.000261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Timestamp   Value  Volume  Volatility\n",
       "0 2025-01-30 09:30:00.740000+00:00  694.24    13.0    0.000260\n",
       "1 2025-01-30 09:30:00.740000+00:00  694.17    15.0    0.000260\n",
       "2 2025-01-30 09:30:00.740000+00:00  694.17    15.0    0.000261\n",
       "3 2025-01-30 09:30:00.740000+00:00  694.11     8.0    0.000261\n",
       "4 2025-01-30 09:30:00.740000+00:00  694.10   249.0    0.000261"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['return', \"SYMBOL\"], inplace= True)\n",
    "df.rename(columns={'wavelet_vol' : 'Volatility', \n",
    "                  'TIMESTAMP':'Timestamp',\n",
    "                   'VALUE' : 'Value',\n",
    "                   'VOLUME' : 'Volume'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer - Encoder feature engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 1.0488 - Recon: 1.4090 - Temp: 0.0397 - Div: -3.8874 - Vol: 0.1229\n",
      "Epoch 10/10 - Loss: 0.9284 - Recon: 1.2970 - Temp: 0.0180 - Div: -3.8884 - Vol: 0.0921\n",
      "Input shape: (2000, 5)\n",
      "Features shape: (1951, 16)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from Feature_engineering.feature_model import (\n",
    "    VolatilityRegimeFeatureExtractor,\n",
    "    prepare_data_for_model,\n",
    "    train_model\n",
    ")\n",
    "\n",
    "# 1. Load and prepare real data\n",
    "df = pd.read_csv(\"/Users/aleksandr/Desktop/my_data.csv\")\n",
    "\n",
    "# Add time index if not present\n",
    "df['time_idx'] = np.arange(len(df)) / len(df)\n",
    "\n",
    "# 2. Set model parameters\n",
    "# Adjust input_size based on your actual features\n",
    "feature_cols = ['Value', 'Volume', 'Volatility']  # Replace with your actual column names\n",
    "input_size = len(feature_cols)\n",
    "\n",
    "model_params = {\n",
    "    'input_size': input_size,     # Adjusted based on your features\n",
    "    'context_length': 50,         # Adjust based on your needs\n",
    "    'd_model': 64,               # Can increase if you have more complex data\n",
    "    'num_encoder_layers': 3,      # Can increase for more complex patterns\n",
    "    'num_attention_heads': 4,     # Can adjust based on data complexity\n",
    "    'dim_feedforward': 128,       # Can increase for more complex data\n",
    "    'dropout': 0.1,              \n",
    "    'attention_dropout': 0.1,     \n",
    "    'batch_size': 64,            # Adjust based on your data size\n",
    "    'learning_rate': 1e-4        \n",
    "}\n",
    "\n",
    "# 3. Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = VolatilityRegimeFeatureExtractor(**model_params).to(device)\n",
    "\n",
    "# 4. Prepare data\n",
    "time_feature_cols = ['time_idx']\n",
    "\n",
    "train_data = prepare_data_for_model(\n",
    "    df=df,\n",
    "    feature_cols=feature_cols,\n",
    "    context_length=model_params['context_length'],\n",
    "    time_feature_cols=time_feature_cols\n",
    ")\n",
    "\n",
    "# 5. Train model\n",
    "training_params = {\n",
    "    'num_epochs': 10,            # Might need more epochs for real data\n",
    "    'alpha': 0.1,    \n",
    "    'beta': 0.1,     \n",
    "    'gamma': 0.2,    \n",
    "    'verbose': True\n",
    "}\n",
    "\n",
    "history = train_model(\n",
    "    model=model,\n",
    "    train_data=train_data,\n",
    "    **training_params\n",
    ")\n",
    "\n",
    "# 6. Extract features\n",
    "features = model.extract_features(\n",
    "    values=train_data['values'].to(device),\n",
    "    time_features=train_data['time_features'].to(device),\n",
    "    attention_mask=train_data['attention_mask'].to(device)\n",
    ")\n",
    "\n",
    "# Convert to numpy array\n",
    "features_np = features.cpu().detach().numpy()\n",
    "\n",
    "print(\"Input shape:\", df.shape)\n",
    "print(\"Features shape:\", features_np.shape)\n",
    "\n",
    "# 7. Save the trained model\n",
    "#torch.save(model.state_dict(), 'volatility_regime_model.pth')\n",
    "\n",
    "# 8. Optional: Save the extracted features\n",
    "#features_df = pd.DataFrame(features_np)\n",
    "#features_df.to_csv('extracted_features.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
